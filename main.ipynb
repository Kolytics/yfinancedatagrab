{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "0a56ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "92225478-c812-419c-b472-78b6ac2d5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_max_history(ticker: str) -> pd.DataFrame:\n",
    "    \"\"\"Using yahoo finance, fetch max pricing history.\n",
    "    Export to file and also return the data.\"\"\"\n",
    "    # Historical and adjusted\n",
    "    yf_stock = yf.Ticker(ticker)\n",
    "    yf_history = yf_stock.history(period=\"max\")\n",
    "    yf_history.to_csv(f\"data/adjusted/{ticker}.csv\")\n",
    "    # unadjusted data:\n",
    "    unadjusted_history = yf.download([ticker], period=\"max\")\n",
    "    unadjusted_history.to_csv(f\"data/unadjusted/{ticker}.csv\")\n",
    "    return yf_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "021788c3-1735-44f3-987a-15cd0f4a2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_stocks(stocks: pd.DataFrame) -> None:\n",
    "    \"\"\"Iterates through list of stocks dataframe\n",
    "    and fetches max history\"\"\"\n",
    "    for i, v in stocks.iterrows():\n",
    "        print(\"Processing: \", i, v['Ticker'])\n",
    "        fetch_max_history(v['Ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "4177d9a2-14f4-44dc-8737-636951f92012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_returns(returns):\n",
    "    res = (returns + 1.0).cumprod()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "92d32908-9a07-49b0-8a66-8652d1b6aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of stock data from file.\n",
    "stocks = pd.read_csv(\"stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "2c3c402c-e8fc-4874-8d2f-4ae89e8d6718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  0 SGRO.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  1 LAND.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  2 BLND.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  3 UTG.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  4 DLN.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  5 BBOX.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  6 LMP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  7 AGR.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  8 BYG.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  9 PHP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  10 GRI.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  11 SHB.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  12 SAFE.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  13 GPOR.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  14 WKP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  15 CAPC.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  16 SRE.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  17 CLI.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  18 UKCM.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  19 HMSO.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  20 DIGS.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  21 LXI.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  22 BCPT.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  23 THRL.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  24 HLCL.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  25 BOXE.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  26 PCTN.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  27 ESP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  28 SUPR.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  29 STP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  30 ^FTSE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  31 ^FTLC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing:  32 IUKP.L\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download each stock into an individual CSV\n",
    "fetch_all_stocks(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "aecbb410-b5cd-4cc3-a783-0375fe20cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stocks into a list and add the index=FTSE100\n",
    "list_stocks = list(stocks['Ticker']) # Convert the pandas to a list of tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "d1e27378-038c-407a-ade3-913d35fc337c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  33 of 33 completed\n"
     ]
    }
   ],
   "source": [
    "# Download and export all of stock data\n",
    "all_stocks = yf.download(list_stocks , start=\"1980-01-01\") # Download the data\n",
    "all_stocks.to_csv('data/all_stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "a9641cf6-c086-4d00-b941-c0e263c85073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_between_dates(frame: pd.DataFrame,\n",
    "                             start_date: str,\n",
    "                             end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Get the prices between two dates. The dates are inclusive.\"\"\"\n",
    "    mask = (all_stocks.index >= start_date) & (all_stocks.index <= end_date)\n",
    "    return frame.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "d6da9751-610e-4954-b962-1720890dcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_matrix(stocks: pd.DataFrame,\n",
    "                       asset: str = None,\n",
    "                       freq: str = 'daily') -> pd.DataFrame:\n",
    "    µ = stocks['Adj Close']\n",
    "\n",
    "    # If we have NaNs, find the first valid index\n",
    "    if asset != None:\n",
    "        if math.isnan(µ[asset][0]):\n",
    "            µ = µ.loc[µ.index >= µ[asset].first_valid_index()]\n",
    "\n",
    "    if freq=='monthly':\n",
    "        µ = µ.resample('BM').apply(lambda x: x[-1]).pct_change()\n",
    "    elif freq=='annual':\n",
    "        µ = µ.resample('BA').apply(lambda x: x[-1]).pct_change()\n",
    "    else:\n",
    "        µ = µ.pct_change()\n",
    "    \n",
    "    return µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "c395983c-4f5b-47c3-bf21-e8dae5c4d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(stocks: pd.DataFrame,\n",
    "          asset1: str, # should be e.g. ^FTSE\n",
    "          asset2: str,\n",
    "          freq: str = 'daily') -> np.ndarray:\n",
    "    \"\"\"Get the Alpha and Beta for two assets by applying linear regression.\"\"\"\n",
    "    µ = clean_stock_matrix(stocks, freq=freq, asset=asset2)\n",
    "\n",
    "    X = np.array(µ[asset1][1:])\n",
    "    y = np.array(µ[asset2][1:])\n",
    "    X_b = np.c_[np.ones(X.shape), X] # set bias term to 1 for each sample\n",
    "    # normal equationn(X.T * X)^(-1) * X.T * y \n",
    "    return np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "3240be94-a0ec-4e24-965a-ec246df56679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(stocks, asset1: str = None, asset2: str = None, freq: str ='daily'):\n",
    "    \"\"\"Calculate the covariance for two assets.\"\"\"\n",
    "    µ = clean_stock_matrix(stocks, freq=freq, asset=asset1)\n",
    "    cov = µ[1:].cov()\n",
    "    if asset1 != None and asset2 != None:\n",
    "        return cov[asset1][asset2]\n",
    "    else:\n",
    "        return cov\n",
    "    \n",
    "def calculate_beta_using_cov(cov, cov_matrix: pd.DataFrame, stock1, stock2):\n",
    "    return cov[stock1][stock2]/np.var(cov_matrix['Adj Close'][stock2].pct_change()[1:], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c61060-dddd-48bd-9622-c3210d8f6371",
   "metadata": {},
   "source": [
    "# Load all stock data from CSV\n",
    "* **input**: start_date, end_date, freq = monthly or daily\n",
    "* **output**: DataFrame with β, α, and cov for each of the stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "18486ee9-2a35-4dd1-a701-dade4c3cd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Data should be c.14mb\n",
    "loaded_stocks = pd.read_csv('data/all_stocks.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "7546144f-037b-4480-bf07-7335c1e3a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a specific date range\n",
    "# The index of the DataFrame is the Date\n",
    "stock_range1 = get_prices_between_dates(all_stocks, '2016-06-01', '2021-06-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "e6e5b7e0-944f-4fc7-82c7-e89fde427121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.24476448260377914\n",
      "Beta:  1.3095637888293217\n"
     ]
    }
   ],
   "source": [
    "# Apply the regression and get the coeff for a specific stock\n",
    "params = slope(stock_range1, '^FTSE', 'SGRO.L', freq='annual')\n",
    "print('Alpha: ', params[0])\n",
    "print('Beta: ', params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980fec2-09a6-4a4f-ae7b-fcbdc5e177c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12f4dd82-3537-4596-8310-f48878b4a6a7",
   "metadata": {},
   "source": [
    "## Get β, α, and covariance for each of the stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "fa6f3a99-4d4f-4602-8fa3-df80f84e0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_beta(row):\n",
    "    params = slope(stock_range1, '^FTSE', row.Ticker, freq='daily')\n",
    "    return params[1]\n",
    "\n",
    "def df_alpha(row):\n",
    "    params = slope(stock_range1, '^FTSE', row.Ticker, freq='daily')\n",
    "    return params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "d348fe24-e0b3-4cb2-bdd6-002f13bdf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ['^FTSE', '^FTLC', 'IUKP.L']\n",
    "rangex = ['daily', 'monthly', 'annual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "bbef6dca-d8c3-48b1-a8b3-0229c33daa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stocks = stocks\n",
    "for r in rangex:\n",
    "    cov = covariance(stock_range1, freq=r)\n",
    "    cov.to_csv(f'data/cov_{r}_range.csv')\n",
    "    for index in indices:\n",
    "        new_stocks[f'Beta ({index})'] = stocks.apply(lambda row: slope(stock_range1, index, row.Ticker, freq=r)[1], axis = 1)\n",
    "        new_stocks[f'Alpha ({index})'] = stocks.apply(lambda row: slope(stock_range1, index, row.Ticker, freq=r)[0], axis = 1)\n",
    "        new_stocks[f'Covariance ({index})'] = stocks.apply(lambda row: cov[row.Ticker][index], axis = 1)\n",
    "    new_stocks.to_csv(f'data/{r}_range_stocks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b901e-0b8e-4f6a-b08b-4668cb175fe4",
   "metadata": {},
   "source": [
    "\n",
    "# Testing with GOOG and SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "2f99440c-1182-445e-acdd-f69f34f5608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    }
   ],
   "source": [
    "# Testing with GOOG and SPY\n",
    "# Download the data\n",
    "g = yf.download(['GOOG', 'BLND.L', 'SPY'] , start=\"2016-06-30\") # Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "1f4272b7-008c-4c0a-b728-8e911d0d617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0006474998508266576\n",
      "Beta:  0.21038920445110254\n"
     ]
    }
   ],
   "source": [
    "# Apply the regression and get the coeffs\n",
    "params = slope(g, 'BLND.L', 'SPY', freq='daily')\n",
    "print('Alpha: ', params[0])\n",
    "print('Beta: ', params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef7425-00b0-4c43-b1f1-0fd88c4a2f32",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "cb669b9f-b69a-486d-92e7-4de5452d4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cov_1x1(row):\n",
    "    return covariance(stock_range1, row.Ticker, '^FTSE', freq='daily')\n",
    "stocks['Covariance'] = stocks.apply(apply_cov_1x1, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
